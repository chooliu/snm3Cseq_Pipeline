{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A04_mapping_bismark overall cmds ===========================================\n",
    "\n",
    "# qsub Scripts/A04a_bismark_map_TAURUS.sub # †\n",
    "# qsub Scripts/A04b_check_bismark.sub \n",
    "# qsub Scripts/A04c_coverage.sub # †\n",
    "\n",
    "# # * = job array based on \"platenum\"\n",
    "# # † = job array based on \"batchnum\" (two rows at a time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A04a_bismark_map_TAURUS.sub\n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -o sublogs/A04a_bismark.$JOB_ID.$TASK_ID\n",
    "#$ -j y\n",
    "#$ -l h_rt=12:00:00,h_data=8G\n",
    "#$ -pe shared 4\n",
    "#$ -N A04a_bismark\n",
    "#$ -t 1-512\n",
    "#$ -hold_jid_ad A03a_trim\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# environment init -------------------------------------------------------------\n",
    "\n",
    ". /u/local/Modules/default/init/modules.sh # <--\n",
    "module load anaconda3 # <--\n",
    "conda activate snm3Cseq_taurus # <--\n",
    "\n",
    "export $(cat snm3C_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "skip_complete=true # <-- for help with incomplete jobs\n",
    "overwrite_partial=true # <-- for help with incomplete jobs\n",
    "\n",
    "# note: estimated time is ~20 min/well so h_rt=24:00:00 may be excessive (anticipate ~8hr)\n",
    "# alternatives are to use less time & resubmit if incomplete or change # wells/batch in A01c\n",
    "\n",
    "\n",
    "\n",
    "# extract target filepaths -----------------------------------------------------\n",
    "\n",
    "# helper functions\n",
    "query_metadat () {\n",
    "  awk -F',' -v targetcol=\"$1\" \\\n",
    "      'NR==1 {\n",
    "                for (i=1;i<=NF;i++) {\n",
    "                    if ($i==targetcol) {assayout=i; break} }\n",
    "                print $assayout\n",
    "              }\n",
    "      NR>1 {\n",
    "                print $assayout\n",
    "            }' ${metadat_well}\n",
    "}\n",
    "\n",
    "# extract target wells, print values for log\n",
    "batchnum=($(query_metadat \"batchnum\"))\n",
    "nwells=${#batchnum[@]}\n",
    "\n",
    "target_well_rows=()\n",
    "for ((row=1; row<=nwells; row++))\n",
    "do\n",
    "    if [[ \"${batchnum[$row]}\" == \"$SGE_TASK_ID\" ]]\n",
    "    then\n",
    "        target_well_rows+=($row)\n",
    "    fi\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "# filepaths associated with target rows in well-level metadata -----------------\n",
    "# (generally not customizeable because output names set by bismark)\n",
    "\n",
    "if [[ ! -s mapping_bismark ]]\n",
    "then\n",
    "    mkdir mapping_bismark\n",
    "fi\n",
    "\n",
    "wellprefix=($(query_metadat \"wellprefix\"))\n",
    "dir_well=($(query_metadat \"A04a_dir_bismark\"))\n",
    "\n",
    "# trimmed .fastqs for input to mapping\n",
    "fastq_r1p=($(query_metadat \"A03a_fqgz_paired_R1\"))\n",
    "fastq_r2p=($(query_metadat \"A03a_fqgz_paired_R2\"))\n",
    "fastq_r1singletrim=($(query_metadat \"A03a_fqgz_singletrim_R1\"))\n",
    "fastq_r2singletrim=($(query_metadat \"A03a_fqgz_singletrim_R2\"))\n",
    "\n",
    "# TAURUS-related files\n",
    "r1unmap=r1unmap.fq.gz\n",
    "r2unmap=r2unmap.fq.gz\n",
    "\n",
    "# final files to check\n",
    "log_picard=($(query_metadat \"A04a_log_picard\"))\n",
    "log_R2P3=($(query_metadat \"A04a_bismarktxt_R2p3\"))\n",
    "bam_final=($(query_metadat \"A04a_bam_final\"))\n",
    "\n",
    "\n",
    "\n",
    "# print target files -----------------------------------------------------------\n",
    "\n",
    "echo \"batch number: $SGE_TASK_ID\"\n",
    "echo \"processing the following rows in well metadata file ($metadat_well):\"\n",
    "for row in ${target_well_rows[@]}\n",
    "    do\n",
    "        echo -e \"$row\\t${wellprefix[$row]}\"\n",
    "    done\n",
    "echo -e \"\\n\\n\"\n",
    "\n",
    "\n",
    "# for each well in batch, apply mC map & quant\n",
    "# (could add check here to skip rows where no trimming output,\n",
    "# but since done by well doesn't cause catastrophic problems)\n",
    "for row in ${target_well_rows[@]} \n",
    "do\n",
    "\n",
    "    # check for existing mapping output\n",
    "    # if final outputs exist, skip; else run mapping .bam\n",
    "    cd $dir_proj\n",
    "    \n",
    "    if [[ -s ${log_R2P3[$row]} \\\n",
    "        && -s ${log_picard[$row]} \\\n",
    "        && -s ${bam_final[$row]} \\\n",
    "        && \"$skip_complete\"==\"true\" ]]\n",
    "    then\n",
    "        echo -e \"final alignments for '${wellprefix[$row]}' already exist. skipping this well.'\"\n",
    "    else\n",
    "    \n",
    "        echo -e \"\\n\\napplying bismark to '${wellprefix[$row]}'...\\n\\n\"\n",
    "\n",
    "        # remove old directory if one exists to deal with incomplete files\n",
    "        # albeit the only major issues are .bai and .tbi indices \n",
    "        # (these often are not overwritten by software in the pipeline,\n",
    "        # resulting in \"index is older than file\" errors later on)\n",
    "        if [[ -e mapping_bismark/${wellprefix[$row]} && \"$overwrite_partial\" == \"true\" ]]\n",
    "        then\n",
    "            echo -e \"\\n\\nWARNING: folder for '${wellprefix[$row]}' exists, but not its final allc files.\"\n",
    "            echo \"because overwrite_partial=true, deleting the directory and re-mapping.\"\n",
    "            rm -rf mapping_bismark/${wellprefix[$row]}\n",
    "        fi\n",
    "        \n",
    "        mkdir $dir_proj/${dir_well[$row]}\n",
    "        cd $dir_proj/${dir_well[$row]}\n",
    "        \n",
    "    # (A) run bismark two-stage\" mapping -------------------------------------\n",
    "    # in: .fastqs from trimming: four .fastqs,\n",
    "    #     properly paired ($fastq_r2p, $fastq_r1p) and trimming singletons\n",
    "    #    ($fastq_r1singletrim, $fastq_r2singletrim)\n",
    "    # out: - paired-end alignments out ($bam_pe, $bam_pe_unmap1, $bam_pe_unmap2)\n",
    "    #      - single-end .bam alignments out ($bam_single1, $bam_single2)\n",
    "    #      - key log files (e.g., mapping rate) \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # TAURUS mapping step 1 -----------------------------------------------\n",
    "        # (Ai.) first pass, full length reads [2 to 7 minutes each read]\n",
    "        bismark $ref_dir_bowtie1 --multicore 3 --bowtie1 --pbat --un -se \\\n",
    "                $dir_proj/${fastq_r1p[$row]},$dir_proj/${fastq_r1singletrim[$row]}\n",
    "        bismark $ref_dir_bowtie1 --multicore 3 --bowtie1 --un -se  \\\n",
    "                $dir_proj/${fastq_r2p[$row]},$dir_proj/${fastq_r2singletrim[$row]}\n",
    "             \n",
    "        # aggregate unmapped reads [<1 min]\n",
    "        cat *R1*_unmapped_reads.fq.gz > $r1unmap\n",
    "        cat *R2*_unmapped_reads.fq.gz > $r2unmap\n",
    "\n",
    "\n",
    "        # umapped read-splitting ---------------------------------------------\n",
    "\n",
    "        # TAURUS-MH style read-splitting [<1 min per split, usually <1 min tot]\n",
    "        # read 1 - first 40bp (requires min length of 80)\n",
    "        seqkit seq -m 80 $r1unmap \\\n",
    "              | seqkit subseq -r 1:40 \\\n",
    "              | seqkit replace -p \"_1:N:0\" -r \"_1:P1:N:0\" > subseq_R1_1.fq\n",
    "        # middle (min length needed 30)\n",
    "        seqkit seq -m 110 $r1unmap \\\n",
    "              | seqkit subseq -r 41:-41 \\\n",
    "              | seqkit replace -p \"_1:N:0\" -r \"_1:P2:N:0\" > subseq_R1_2.fq\n",
    "        # last 40bp\n",
    "        seqkit seq -m 80 $r1unmap \\\n",
    "              | seqkit subseq -r -40:-1 \\\n",
    "              | seqkit replace -p \"_1:N:0\" -r \"_1:P3:N:0\" > subseq_R1_3.fq\n",
    "              \n",
    "        # read 2\n",
    "        # first 40bp (requires min length of 80)\n",
    "        seqkit seq -m 80 $r2unmap \\\n",
    "              | seqkit subseq -r 1:40 \\\n",
    "              | seqkit replace -p \"_2:N:0\" -r \"_2:P1:N:0\" > subseq_R2_1.fq\n",
    "        # middle (min length after trim 30)\n",
    "        seqkit seq -m 110 $r2unmap \\\n",
    "              | seqkit subseq -r 41:-41 \\\n",
    "              | seqkit replace -p \"_2:N:0\" -r \"_2:P2:N:0\" > subseq_R2_2.fq\n",
    "        # last 40bp\n",
    "        seqkit seq -m 80 $r2unmap \\\n",
    "              | seqkit subseq -r -40:-1 \\\n",
    "              | seqkit replace -p \"_2:N:0\" -r \"_2:P3:N:0\" > subseq_R2_3.fq\n",
    "\n",
    "\n",
    "        # TAURUS step 2 --------------------------------------------------\n",
    "        \n",
    "        # single-end, R1, [<2 minutes per read substring]\n",
    "        bismark $ref_dir_bowtie1 --multicore 3 --bowtie1 --pbat -se \\\n",
    "                subseq_R1_1.fq,subseq_R1_2.fq,subseq_R1_3.fq\n",
    "                \n",
    "        # single-end, R2\n",
    "        bismark $ref_dir_bowtie1 --multicore 3 --bowtie1 -se \\\n",
    "                subseq_R2_1.fq,subseq_R2_2.fq,subseq_R2_3.fq\n",
    "\n",
    "\n",
    "        # merge & dedupe ------------------------------------------------\n",
    "\n",
    "        # merge & sort all alignments [<3 min]\n",
    "        samtools merge -f merged.bam *bismark.bam\n",
    "        samtools sort -o merged_sorted.bam merged.bam\n",
    "        \n",
    "        # deduplication [<1-2 min]\n",
    "        picard MarkDuplicates I=merged_sorted.bam  \\\n",
    "            OPTICAL_DUPLICATE_PIXEL_DISTANCE=2500 \\\n",
    "            ADD_PG_TAG_TO_READS=false REMOVE_DUPLICATES=true \\\n",
    "            O=merged_dedupe.bam M=picard.log\n",
    "\n",
    "        # if fails quickcheck,\n",
    "        # remove final file to force re-running this well / skip in subsequent steps\n",
    "        samtools quickcheck merged_dedupe.bam \\\n",
    "            || rm merged_dedupe.bam && echo \"quickcheck error with ${wellprefix[$row]}?\"\n",
    "        \n",
    "        samtools index merged_dedupe.bam\n",
    "        \n",
    "        # optionally cleanup files --------------------------------------\n",
    "        # (empty-var check to avoid broad deletion of .bam files)\n",
    "        if [[ ! -z \"$wellprefix\" ]]\n",
    "        then\n",
    "        echo 'clearing intermediate files for ${wellprefix[$row]}.'\n",
    "            rm subseq_*.fq\n",
    "            rm *.fq.gz\n",
    "            rm ${wellprefix[$row]}*bam\n",
    "            rm subseq*bam\n",
    "            rm merged.bam\n",
    "            rm merged_sorted.bam\n",
    "        fi\n",
    "    fi\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "echo -e \"\\n\\n'A04a_bismark' completed.\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `date `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A04b_check_bismark.sub\n",
    "\n",
    "# #!/bin/bash\n",
    "# #$ -cwd\n",
    "# #$ -o sublogs/A04b_check_bismark.$JOB_ID\n",
    "# #$ -j y\n",
    "# #$ -l h_rt=2:00:00,h_data=4G\n",
    "# #$ -N A04b_bischeck\n",
    "# #$ -hold_jid A04a_bismark\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# environment init -------------------------------------------------------------\n",
    "\n",
    "export $(cat snm3C_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "\n",
    "\n",
    "# extract target filepaths -----------------------------------------------------\n",
    "\n",
    "query_metadat () {\n",
    "  awk -F',' -v targetcol=\"$1\" \\\n",
    "      'NR==1 {\n",
    "                for (i=1;i<=NF;i++) {\n",
    "                    if ($i==targetcol) {assayout=i; break} }\n",
    "                print $assayout\n",
    "              } \n",
    "      NR>1 {\n",
    "                print $assayout\n",
    "            }' $metadat_well\n",
    "}\n",
    "\n",
    "check_filepaths_in_assay() {\n",
    "    for file in $@\n",
    "        do \n",
    "        if [[ ! -s $file ]]\n",
    "            then\n",
    "                echo \"missing '$file'\"\n",
    "            fi\n",
    "        done\n",
    "}\n",
    "\n",
    "check_filepath_by_batch() {\n",
    "target_array=($@)\n",
    "batches_to_rerun=()\n",
    "for ((target_batch=1; target_batch<=nbatches; target_batch++))\n",
    "    do\n",
    "        target_well_rows=()\n",
    "        for ((row=1; row<=nwells; row++))\n",
    "        do\n",
    "            if [[ \"${batchnum[$row]}\" == \"${target_batch}\" ]]\n",
    "            then\n",
    "                target_well_rows+=($row)\n",
    "            fi\n",
    "        done\n",
    "\n",
    "        batch_file_list=${target_array[@]: ${target_well_rows[0]}:${#target_well_rows[@]} }\n",
    "    \n",
    "        num_files_missing=$(check_filepaths_in_assay ${batch_file_list[@]} | wc -l)\n",
    "\n",
    "        if [[ ${num_files_missing} > 0 ]]\n",
    "        then\n",
    "            batches_to_rerun+=(${target_batch})\n",
    "            echo -e \"${target_batch} \\t ${num_files_missing}\"\n",
    "        fi\n",
    "    done \n",
    "    \n",
    "    if [[ ${#batches_to_rerun[@]} > 0 ]]\n",
    "    then\n",
    "        echo \"batches to re-run:\"\n",
    "        echo \"${batches_to_rerun[*]}\"        \n",
    "    fi\n",
    "}\n",
    "\n",
    "batchnum=($(query_metadat \"batchnum\"))\n",
    "\n",
    "nwells=${#batchnum[@]}\n",
    "nbatches=${batchnum[-1]}\n",
    "\n",
    "\n",
    "\n",
    "# apply checks for A04a output -------------------------------------------------\n",
    "\n",
    "echo \"-----------------------------------------------------------------\"\n",
    "echo \"A. printing number of final .bams missing (by batch)... \"\n",
    "echo \"-----------------------------------------------------------------\"\n",
    "\n",
    "log_picard=($(query_metadat \"A04a_log_picard\"))\n",
    "log_R2P3=($(query_metadat \"A04a_bismarktxt_R2p3\"))\n",
    "bam_final=($(query_metadat \"A04a_bam_final\"))\n",
    "\n",
    "echo \"checking final merged .bam:\"\n",
    "echo -e \"batchnum\\tnum_missing\"\n",
    "check_filepath_by_batch ${bam_final[@]}\n",
    "\n",
    "echo \"checking singleton trimming .log:\"\n",
    "check_filepath_by_batch ${log_R2P3[@]}\n",
    "\n",
    "echo \"checking picard .log:\"\n",
    "check_filepath_by_batch ${picard_log[@]}\n",
    "\n",
    "echo \"checking trimming logs:\"\n",
    "check_filepath_by_batch ${trimming_log[@]}\n",
    "\n",
    "echo -e \"\\n\\nsuggest re-running and checking sublog output of above batches.\"\n",
    "\n",
    "\n",
    "\n",
    "echo -e \"\\n\\n-----------------------------------------------------------------\"\n",
    "echo \"B. checking each expected .bam file (from $metadat_well)\"\n",
    "echo -e \"-----------------------------------------------------------------\\n\"\n",
    "\n",
    "echo -e \"\\nchecking final .bam file:\\n\"\n",
    "check_filepaths_in_assay ${final_bam[@]}\n",
    "\n",
    "echo -e \"\\nchecking R2:P3 singleton trimming file:\\n\"\n",
    "check_filepaths_in_assay ${log_R2P3[@]}\n",
    "\n",
    "echo -e \"\\nchecking picard .log:\\n\"\n",
    "check_filepaths_in_assay ${picard_log[@]}\n",
    "\n",
    "echo -e \"\\ncompare to the number of trimmed .fastq sets in:\\n\"\n",
    "echo -e \"(using .json as proxy):\\n\"\n",
    "check_filepaths_in_assay ${trimming_log[@]}\n",
    "\n",
    "echo -e \"\\n* checks the A04a output columns of 'metadat_well' if the file exists and is non-empty.\"\n",
    "echo \"* if none missing, will only output target column names above.\"\n",
    "echo \"* if some declared 'missing' but all other checks OK, may just be no/few reads surviving trimming.\"\n",
    "echo \"  (check 'fastq_demultip/' and associated fastp logs e.g., fastq_trimmed/wellprefix.html report)\"\n",
    "\n",
    "\n",
    "\n",
    "echo -e \"\\n\\n-----------------------------------------------------------------\"\n",
    "echo \"C. checking log files for issues.\"\n",
    "echo -e \"-----------------------------------------------------------------\\n\"\n",
    "\n",
    "echo \"checking if 'completed' in sublogs/A04a_bismark* output.\"\n",
    "echo \"if any filename is printed, the associated batch may have not completed mapping.\"\n",
    "\n",
    "grep -c 'ended on' sublogs/A04a_bismark* | awk -F \":\" '$2==0 {print $1}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "echo -e \"\\n\\n'A04b_bischeck' completed.\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID ended on:   \" `date `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ../Scripts/A04c_coverage.sub\n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd\n",
    "#$ -o sublogs/A04c_coverage.$JOB_ID.$TASK_ID\n",
    "#$ -j y\n",
    "#$ -l h_rt=6:00:00,h_data=16G\n",
    "#$ -N A04c_coverage\n",
    "#$ -t 1-512\n",
    "#$ -hold_jid_ad A04a_bismark\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID started on:   \" `date `\n",
    "echo \" \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# environment init -------------------------------------------------------------\n",
    "\n",
    ". /u/local/Modules/default/init/modules.sh # <--\n",
    "module load anaconda3 # <--\n",
    "conda activate snm3Cseq_taurus # <--\n",
    "\n",
    "export $(cat snm3C_parameters.env | grep -v '^#' | xargs) # <--\n",
    "\n",
    "skip_complete=true # <-- for help with incomplete jobs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# extract target filepaths -----------------------------------------------------\n",
    "\n",
    "# helper functions\n",
    "query_metadat () {\n",
    "  awk -F',' -v targetcol=\"$1\" \\\n",
    "      'NR==1 {\n",
    "                for (i=1;i<=NF;i++) {\n",
    "                    if ($i==targetcol) {assayout=i; break} }\n",
    "                print $assayout\n",
    "              }\n",
    "      NR>1 {\n",
    "                print $assayout\n",
    "            }' $metadat_well\n",
    "}\n",
    "\n",
    "# extract target wells, print values for log\n",
    "\n",
    "batchnum=($(query_metadat \"batchnum\"))\n",
    "nwells=${#batchnum[@]}\n",
    "\n",
    "target_well_rows=()\n",
    "for ((row=1; row<=nwells; row++))\n",
    "do\n",
    "    if [[ \"${batchnum[$row]}\" == \"$SGE_TASK_ID\" ]]\n",
    "    then\n",
    "        target_well_rows+=($row)\n",
    "    fi\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "# filepaths associated with target rows in well-level metadata -----------------\n",
    "\n",
    "wellprefix=($(query_metadat \"wellprefix\"))\n",
    "dir_well=($(query_metadat \"A04a_dir_bismark\"))\n",
    "\n",
    "final_bam=($(query_metadat \"A04a_bam_final\"))\n",
    "\n",
    "outsamstats=($(query_metadat \"A04c_txt_samstats\")) # 'samstats.txt' by default\n",
    "outcovstats=($(query_metadat \"A04c_txt_covnsites\")) # 'nbases_cov_by_chr.txt'\n",
    "outcovtot=($(query_metadat \"A04c_txt_covtot\")) # 'total_cov_by_chr.txt'\n",
    "\n",
    "\n",
    "\n",
    "# samtools stats on each well in the batch -------------------------------------\n",
    "\n",
    "for row in ${target_well_rows[@]} \n",
    "do\n",
    "\n",
    "    cd ${dir_proj}\n",
    "    \n",
    "    if [[ -s ${dir_proj}/${outsamstats[$row]} \\\n",
    "        && -s ${dir_proj}/${outcovstats[$row]} \\\n",
    "        && -s ${dir_proj}/${outcovtot[$row]} ]]\n",
    "    then\n",
    "        echo -e \"coverage output for '${wellprefix[$row]}' already exists.\"\n",
    "                \n",
    "        if [[ \"${skip_complete}\" == \"true\" ]]\n",
    "        then\n",
    "            echo \"skip_complete == true. skipping this well.'\"\n",
    "            continue\n",
    "        else\n",
    "            echo \"skip_complete != true. re-running this well.'\"\n",
    "        fi\n",
    "    fi\n",
    "    \n",
    "    if [[ ! -s ${dir_proj}/${final_bam[$row]} ]]\n",
    "    then\n",
    "        echo -e \"input .bam for '${wellprefix[$row]}' seems to be missing. skipping.\\n\\n\"\n",
    "    fi\n",
    "\n",
    "    echo -e \"\\n\\nprofiling .bams from '${wellprefix[$row]}'...\\n\\n\"\n",
    "\n",
    "    cd ${dir_well[$row]}\n",
    "\n",
    "    # run samtools stats\n",
    "    samtools stats ${dir_proj}/${final_bam[$row]} | grep '^SN' | cut -f 2,3 > ${dir_proj}/${outsamstats[$row]}\n",
    "\n",
    "    # use samtools mpileup for total coverage\n",
    "    samtools mpileup ${dir_proj}/${final_bam[$row]} | cut -f 1,4 > tmp_coverage_mpileup\n",
    "\n",
    "    # aggregate by chromosome\n",
    "    # (useful for sex-checks)\n",
    "    cut -f 1 tmp_coverage_mpileup | uniq -c > ${dir_proj}/${outcovstats[$row]}\n",
    "    awk '{covsums[$1]+=$2} END {for (key in covsums) printf(\"%s\\t%s\\n\", key, covsums[key])}' \\\n",
    "        tmp_coverage_mpileup > ${dir_proj}/${outcovtot[$row]}\n",
    "    rm tmp_coverage_mpileup\n",
    "\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "echo -e \"\\n\\n'A04c_coverage' completed.\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `hostname -s`\n",
    "echo \"Job $JOB_ID.$SGE_TASK_ID ended on:   \" `date `\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
